{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305cf06-7818-4749-89b7-25e4b1904db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr jiwer nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11008d23-a5a8-46d6-92b0-13de8f347040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import pyttsx3\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from jiwer import wer, cer\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b955263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTS Response Time for 'fiction section to right': 6.32s\n",
      "TTS Response Time for '8': 1.51s\n",
      "TTS Response Time for '0': 0.50s\n",
      "TTS Response Time for '81': 0.42s\n",
      "TTS Response Time for '87': 0.07s\n"
     ]
    }
   ],
   "source": [
    "# Init Text-to-Speech (Windows sapi5)\n",
    "\n",
    "engine = pyttsx3.init('sapi5')\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 1)\n",
    "\n",
    "# Queue to hold texts to speak\n",
    "speech_queue = queue.Queue()\n",
    "\n",
    "# Store metrics\n",
    "ocr_metrics_list = []\n",
    "tts_metrics_list = []\n",
    "detected_text_list = []\n",
    "\n",
    "def tts_worker():\n",
    "    while True:\n",
    "        text = speech_queue.get()\n",
    "        if text is None:  # Signal to stop the thread\n",
    "            break\n",
    "\n",
    "        # --- Measure TTS Response Time ---\n",
    "        start_time = time.time()\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        response_time = time.time() - start_time\n",
    "\n",
    "        tts_metrics_list.append({\n",
    "            \"text\": text,\n",
    "            \"response_time\": response_time\n",
    "        })\n",
    "\n",
    "        print(f\"TTS Response Time for '{text}': {response_time:.2f}s\")\n",
    "        speech_queue.task_done()\n",
    "\n",
    "# Start the TTS thread\n",
    "thread = threading.Thread(target=tts_worker, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b95dc-9b70-479a-951d-771ae782a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "C:\\Users\\vansh\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing for speech: fiction section to right\n",
      "OCR Metrics for 'fiction section to right': CER=0.00, WER=0.00, BLEU=1.00\n",
      "Queueing for speech: 8\n",
      "OCR Metrics for '8': CER=0.00, WER=0.00, BLEU=0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing for speech: 0\n",
      "OCR Metrics for '0': CER=0.00, WER=0.00, BLEU=0.00\n",
      "Queueing for speech: 81\n",
      "OCR Metrics for '81': CER=0.00, WER=0.00, BLEU=0.00\n",
      "Queueing for speech: 87\n",
      "OCR Metrics for '87': CER=0.00, WER=0.00, BLEU=0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = reader.readtext(frame)\n",
    "\n",
    "    for (bbox, text, prob) in results:\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, text, (top_left[0], top_left[1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cleaned_text = text.strip()\n",
    "        if cleaned_text and cleaned_text not in detected_text_list:\n",
    "            detected_text_list.append(cleaned_text)\n",
    "            print(f\"Queueing for speech: {cleaned_text}\")\n",
    "            speech_queue.put(cleaned_text)  # Add text to TTS queue\n",
    "\n",
    "            # --- Evaluate OCR (if you have ground truth available) ---\n",
    "            # For demo: assume ground truth = cleaned_text (self-comparison)\n",
    "            ground_truth = cleaned_text\n",
    "            ocr_output = cleaned_text   # Replace with OCR output if comparing\n",
    "            cer_score = cer(ground_truth, ocr_output)\n",
    "            wer_score = wer(ground_truth, ocr_output)\n",
    "            bleu_score = sentence_bleu([ground_truth.split()], ocr_output.split())\n",
    "\n",
    "            ocr_metrics_list.append({\n",
    "                \"text\": cleaned_text,\n",
    "                \"CER\": cer_score,\n",
    "                \"WER\": wer_score,\n",
    "                \"BLEU\": bleu_score\n",
    "            })\n",
    "\n",
    "            print(f\"OCR Metrics for '{cleaned_text}': CER={cer_score:.2f}, WER={wer_score:.2f}, BLEU={bleu_score:.2f}\")\n",
    "\n",
    "    cv2.imshow(\"Live OCR with Speech\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ===============================\n",
    "# Cleanup\n",
    "# ===============================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "speech_queue.put(None)\n",
    "thread.join()\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(\"Detected Texts:\")\n",
    "for i, t in enumerate(detected_text_list, 1):\n",
    "    print(f\"{i}. {t}\")\n",
    "\n",
    "print(\"\\nOCR Metrics Collected:\")\n",
    "for m in ocr_metrics_list:\n",
    "    print(m)\n",
    "\n",
    "print(\"\\nTTS Metrics Collected:\")\n",
    "for m in tts_metrics_list:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbe7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
